# Explicaci√≥n Paso a Paso del C√≥digo

## Celda 1: Importaci√≥n de Librer√≠as

```python
import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn import datasets
```

**Prop√≥sito**: Importar todas las librer√≠as necesarias para el an√°lisis.

**Detalles**:
- `numpy` y `pandas`: Manipulaci√≥n de datos
- `seaborn` y `matplotlib`: Visualizaci√≥n
- `%matplotlib inline`: Muestra gr√°ficos dentro del notebook
- `sklearn.datasets`: Acceso a datasets de ejemplo

---

## Celda 2: Carga del Dataset

```python
(X, Y) = datasets.load_wine(return_X_y=True, as_frame=True)
```

**Prop√≥sito**: Cargar el dataset de vinos.

**Detalles**:
- `X`: DataFrame con 13 caracter√≠sticas (variables independientes)
  - Ejemplo: alcohol, √°cido m√°lico, cenizas, alcalinidad, magnesio, fenoles, flavonoides, etc.
- `Y`: Serie con las etiquetas de clase (variable dependiente)
  - 3 clases: 0, 1, 2 (representan diferentes tipos de vino)
- `return_X_y=True`: Retorna X e Y por separado
- `as_frame=True`: Retorna como pandas DataFrame en lugar de arrays numpy

---

## Celda 3: Verificar Dimensiones de X

```python
print('Shape of X:', X.shape)
```

**Prop√≥sito**: Verificar el n√∫mero de filas (muestras) y columnas (caracter√≠sticas).

**Resultado esperado**: `(178, 13)`
- 178 muestras de vinos
- 13 caracter√≠sticas por muestra

---

## Celda 4: Visualizar Primeras Filas

```python
X.head()
```

**Prop√≥sito**: Mostrar las primeras 5 filas del DataFrame.

**Utilidad**:
- Inspeccionar la estructura de los datos
- Verificar nombres de columnas
- Identificar el tipo de valores (flotantes, enteros, etc.)

---

## Celda 5: Dimensiones de Y

```python
Y.shape
```

**Prop√≥sito**: Verificar el tama√±o del vector de etiquetas.

**Resultado esperado**: `(178,)`
- 178 etiquetas (una por cada muestra)

---

## Celda 6: Distribuci√≥n de Clases

```python
Y.groupby(Y).count()
```

**Prop√≥sito**: Contar cu√°ntas muestras hay de cada clase.

**Utilidad**:
- Verificar si el dataset est√° balanceado
- Entender la distribuci√≥n de clases

**Interpretaci√≥n**:
- Muestra cu√°ntos vinos de cada tipo hay en el dataset

---

## Celda 7: Importar el Clasificador

```python
from sklearn.tree import DecisionTreeClassifier
```

**Prop√≥sito**: Importar el algoritmo de √Årbol de Decisi√≥n.

---

## Celda 8: Crear Instancia del Modelo

```python
tree_instance = DecisionTreeClassifier(max_depth=2)
```

**Prop√≥sito**: Crear un objeto del clasificador con configuraci√≥n espec√≠fica.

**Par√°metro importante**:
- `max_depth=2`: Limita el √°rbol a 2 niveles de profundidad
  - **Ventaja**: Previene overfitting
  - **Desventaja**: Puede limitar la precisi√≥n del modelo
  - Es un hiperpar√°metro que se puede ajustar

**¬øPor qu√© max_depth=2?**
- √Årbol simple y f√°cil de interpretar
- Bueno para demostraci√≥n educativa
- Reduce complejidad computacional

---

## Celda 9 y 10: Exploraci√≥n con Muestras

```python
X.sample(2)
Y.sample(3)
```

**Prop√≥sito**: Mostrar muestras aleatorias de los datos.

**Utilidad**:
- Verificar la calidad de los datos
- Familiarizarse con los valores t√≠picos

---

## Celda 11: Divisi√≥n de Datos

```python
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)
```

**Prop√≥sito**: Dividir el dataset en conjuntos de entrenamiento y prueba.

**Par√°metros**:
- `random_state=1`: Semilla para reproducibilidad (siempre produce la misma divisi√≥n)
- Divisi√≥n por defecto: 75% entrenamiento, 25% prueba

**Variables resultantes**:
- `X_train`: Caracter√≠sticas para entrenar (‚âà133 muestras)
- `X_test`: Caracter√≠sticas para probar (‚âà45 muestras)
- `Y_train`: Etiquetas para entrenar
- `Y_test`: Etiquetas para probar

**Importancia**:
- Evita overfitting
- Permite evaluar el modelo con datos no vistos durante el entrenamiento

---

## Celda 12: Entrenamiento del Modelo

```python
tree_instance.fit(X_train, Y_train)
```

**Prop√≥sito**: Entrenar el √°rbol de decisi√≥n con los datos de entrenamiento.

**Proceso interno**:
1. El algoritmo busca la mejor caracter√≠stica y punto de corte para dividir los datos
2. Repite el proceso recursivamente hasta alcanzar `max_depth=2`
3. Cada nodo del √°rbol representa una decisi√≥n basada en una caracter√≠stica

**Resultado**: El modelo aprende patrones de los datos de entrenamiento

---

## Celda 13: Contar Nodos

```python
tree_instance.tree_.node_count
```

**Prop√≥sito**: Obtener el n√∫mero total de nodos en el √°rbol.

**Interpretaci√≥n**:
- Con `max_depth=2`, el n√∫mero m√°ximo de nodos ser√≠a 7 (1+2+4)
- Puede ser menor si el √°rbol no necesita ramificarse completamente

---

## Celda 14 y 17: Visualizaci√≥n del √Årbol

```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
plot_tree(tree_instance, feature_names=X_train.columns, filled=True, 
          class_names=True, label='none', impurity=False)
plt.show()
```

**Prop√≥sito**: Visualizar gr√°ficamente el √°rbol de decisi√≥n.

**Par√°metros**:
- `feature_names=X_train.columns`: Muestra nombres reales de caracter√≠sticas
- `filled=True`: Colorea nodos seg√∫n la clase predominante
- `class_names=True`: Muestra nombres de clases
- `label='none'`: No muestra etiquetas adicionales
- `impurity=False`: Oculta la medida de impureza (Gini)

**Interpretaci√≥n del √°rbol**:
- **Nodos internos**: Contienen una condici√≥n (ej: "proline <= 755")
- **Nodos hoja**: Contienen la clasificaci√≥n final
- **Colores**: Representan las diferentes clases de vino

---

## Celda 15: Realizar Predicciones

```python
ypred = tree_instance.predict(X_test)
ypred
```

**Prop√≥sito**: Predecir las clases para el conjunto de prueba.

**Proceso**:
1. Toma cada muestra de `X_test`
2. La pasa por el √°rbol de decisi√≥n entrenado
3. Retorna la clase predicha para cada muestra

**Resultado**: Array con las predicciones (valores: 0, 1, o 2)

---

## Celda 16: Inspecci√≥n de Predicciones

```python
print(X_test.iloc[0:2,[0,6]])
print("Etiquetas: ", ypred[0:2])
```

**Prop√≥sito**: Comparar algunas caracter√≠sticas con sus predicciones.

**Detalles**:
- `.iloc[0:2,[0,6]]`: Selecciona las primeras 2 filas y las columnas 0 y 6
- Muestra c√≥mo el modelo asigna etiquetas bas√°ndose en las caracter√≠sticas

**Utilidad**: Verificar manualmente que las predicciones tienen sentido

---

## Celda 18: Evaluaci√≥n del Modelo - Accuracy Detallado

```python
# Calcular accuracy
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(Y_test, ypred)

# Mostrar resultados detallados
print("="*50)
print("AN√ÅLISIS DE ACCURACY DEL MODELO")
print("="*50)
print(f"\nüìä Accuracy (Precisi√≥n): {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"\nüéØ Predicciones correctas: {(ypred == Y_test).sum()} de {len(Y_test)}")
print(f"‚ùå Predicciones incorrectas: {(ypred != Y_test).sum()} de {len(Y_test)}")
print(f"\nüìà Tasa de acierto: {accuracy*100:.2f}%")
print(f"üìâ Tasa de error: {(1-accuracy)*100:.2f}%")
print("="*50)
```

**Prop√≥sito**: Calcular y mostrar la precisi√≥n (accuracy) del modelo de forma detallada.

**C√°lculo**:
```
Accuracy = Predicciones Correctas / Total de Predicciones
```

**M√©tricas mostradas**:
- **Accuracy**: Porcentaje total de aciertos
- **Predicciones correctas/incorrectas**: Conteo absoluto
- **Tasa de acierto**: Porcentaje de clasificaciones correctas
- **Tasa de error**: Porcentaje de clasificaciones incorrectas

**Interpretaci√≥n**:
- Valor entre 0 y 1 (o 0% y 100%)
- Ejemplo: 0.95 = 95% de precisi√≥n
- Indica qu√© porcentaje de vinos fueron clasificados correctamente

**Limitaciones de accuracy**:
- Puede ser enga√±oso con clases desbalanceadas
- No distingue entre tipos de errores (falsos positivos vs falsos negativos)
- Por eso es importante complementar con otras m√©tricas

---

## Celda 19: An√°lisis Detallado por Clase

```python
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Reporte de clasificaci√≥n completo
print("REPORTE DE CLASIFICACI√ìN DETALLADO")
print("="*60)
print(classification_report(Y_test, ypred, target_names=['Clase 0', 'Clase 1', 'Clase 2']))

# Matriz de confusi√≥n
print("\nMATRIZ DE CONFUSI√ìN")
print("="*60)
cm = confusion_matrix(Y_test, ypred)
print(cm)
print("\nInterpretaci√≥n:")
print("- Filas: Clases reales")
print("- Columnas: Clases predichas")
print("- Diagonal: Predicciones correctas")
```

**Prop√≥sito**: Obtener m√©tricas detalladas por cada clase de vino.

**Classification Report incluye**:
- **Precision**: De todas las predicciones de una clase, cu√°ntas fueron correctas
  - F√≥rmula: TP / (TP + FP)
- **Recall**: De todas las muestras reales de una clase, cu√°ntas fueron detectadas
  - F√≥rmula: TP / (TP + FN)
- **F1-Score**: Media arm√≥nica entre precision y recall
  - F√≥rmula: 2 * (precision * recall) / (precision + recall)
- **Support**: N√∫mero de muestras reales de cada clase

**Matriz de Confusi√≥n**:
- Tabla que muestra predicciones correctas e incorrectas
- **Diagonal principal**: Predicciones correctas
- **Fuera de diagonal**: Errores de clasificaci√≥n
- Permite identificar qu√© clases se confunden entre s√≠

**Ejemplo de interpretaci√≥n**:
```
           Predicho 0  Predicho 1  Predicho 2
Real 0         15          0           0
Real 1          0          13          2
Real 2          0          1           14
```
- La clase 1 se confunde 2 veces con la clase 2
- La clase 2 se confunde 1 vez con la clase 1

---

## Celda 20: Visualizaci√≥n de la Matriz de Confusi√≥n

```python
# Visualizar matriz de confusi√≥n
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Clase 0', 'Clase 1', 'Clase 2'],
            yticklabels=['Clase 0', 'Clase 1', 'Clase 2'],
            cbar_kws={'label': 'N√∫mero de muestras'})
plt.title('Matriz de Confusi√≥n - √Årbol de Decisi√≥n', fontsize=14, fontweight='bold')
plt.ylabel('Clase Real', fontsize=12)
plt.xlabel('Clase Predicha', fontsize=12)
plt.tight_layout()
plt.show()
```

**Prop√≥sito**: Crear una visualizaci√≥n gr√°fica de la matriz de confusi√≥n.

**Par√°metros del heatmap**:
- `cm`: Matriz de confusi√≥n calculada anteriormente
- `annot=True`: Muestra los n√∫meros en cada celda
- `fmt='d'`: Formato decimal (enteros)
- `cmap='Blues'`: Paleta de colores azules
- `xticklabels/yticklabels`: Nombres de las clases
- `cbar_kws`: Configuraci√≥n de la barra de colores

**Ventajas de la visualizaci√≥n**:
- Identificaci√≥n r√°pida de patrones de error
- Colores m√°s intensos = m√°s muestras
- F√°cil de interpretar visualmente
- √ötil para presentaciones

---

## Celda 21: Comparaci√≥n de Predicciones

```python
# Crear DataFrame con resultados
resultados = pd.DataFrame({
    'Clase Real': Y_test.values,
    'Clase Predicha': ypred,
    'Correcto': Y_test.values == ypred
})

print("üìä RESUMEN DE RESULTADOS:")
print("\n‚úÖ Predicciones CORRECTAS:")
print(resultados[resultados['Correcto'] == True].head(10))

print("\n\n‚ùå Predicciones INCORRECTAS:")
incorrectas = resultados[resultados['Correcto'] == False]
if len(incorrectas) > 0:
    print(incorrectas)
else:
    print("¬°No hay predicciones incorrectas! Accuracy del 100%")
```

**Prop√≥sito**: Crear un DataFrame para analizar predicciones individuales.

**Columnas del DataFrame**:
- `Clase Real`: Valor verdadero de Y_test
- `Clase Predicha`: Valor predicho por el modelo
- `Correcto`: Booleano indicando si la predicci√≥n fue correcta

**Utilidad**:
- Inspeccionar casos espec√≠ficos de √©xito o error
- Identificar patrones en las predicciones incorrectas
- Debug del modelo

**An√°lisis de errores**:
- Si hay pocas predicciones incorrectas: buen modelo
- Si todas las incorrectas son de la misma clase: puede haber desbalanceo
- Permite mejorar el modelo enfoc√°ndose en casos problem√°ticos

---

## Flujo Completo del Proyecto

```
1. PREPARACI√ìN
   ‚îú‚îÄ‚îÄ Importar librer√≠as
   ‚îî‚îÄ‚îÄ Cargar dataset

2. EXPLORACI√ìN DE DATOS
   ‚îú‚îÄ‚îÄ Verificar dimensiones (X.shape, Y.shape)
   ‚îú‚îÄ‚îÄ Visualizar muestras (X.head(), X.sample())
   ‚îî‚îÄ‚îÄ Analizar distribuci√≥n de clases (Y.groupby())

3. PREPARACI√ìN DEL MODELO
   ‚îú‚îÄ‚îÄ Importar DecisionTreeClassifier
   ‚îú‚îÄ‚îÄ Crear instancia del clasificador (max_depth=2)
   ‚îî‚îÄ‚îÄ Dividir datos en train/test (75%/25%)

4. ENTRENAMIENTO
   ‚îú‚îÄ‚îÄ Entrenar el modelo (fit())
   ‚îî‚îÄ‚îÄ Analizar estructura (node_count)

5. VISUALIZACI√ìN DEL MODELO
   ‚îú‚îÄ‚îÄ Graficar √°rbol de decisi√≥n (plot_tree)
   ‚îî‚îÄ‚îÄ Interpretar nodos y reglas de decisi√≥n

6. PREDICCIONES
   ‚îú‚îÄ‚îÄ Realizar predicciones (predict())
   ‚îî‚îÄ‚îÄ Inspeccionar predicciones individuales

7. EVALUACI√ìN COMPLETA
   ‚îú‚îÄ‚îÄ Calcular accuracy general
   ‚îú‚îÄ‚îÄ Generar classification report (precision, recall, f1-score)
   ‚îú‚îÄ‚îÄ Crear matriz de confusi√≥n
   ‚îú‚îÄ‚îÄ Visualizar matriz de confusi√≥n (heatmap)
   ‚îú‚îÄ‚îÄ Analizar predicciones correctas e incorrectas
   ‚îî‚îÄ‚îÄ Sacar conclusiones

8. CONCLUSIONES
   ‚îú‚îÄ‚îÄ Interpretar resultados
   ‚îú‚îÄ‚îÄ Identificar ventajas y limitaciones
   ‚îî‚îÄ‚îÄ Proponer mejoras futuras
```

---

## Conceptos Clave de Machine Learning Aplicados

### 1. **Supervisado vs No Supervisado**
- Este es un problema de **aprendizaje supervisado**: tenemos etiquetas (Y)

### 2. **Clasificaci√≥n vs Regresi√≥n**
- EM√©tricas de Evaluaci√≥n Implementadas

### 1. **Accuracy (Precisi√≥n Global)**
- Porcentaje total de predicciones correctas
- F√°cil de interpretar
- ‚ö†Ô∏è Puede ser enga√±osa con clases desbalanceadas

### 2. **Precision (Precisi√≥n por Clase)**
- De las predicciones de una clase, cu√°ntas son correctas
- Importante cuando los falsos positivos son costosos
- Ejemplo: En diagn√≥stico m√©dico

### 3. **Recall (Exhaustividad)**
- De las muestras reales de una clase, cu√°ntas detectamos
- Importante cuando los falsos negativos son costosos
- Ejemplo: Detectar fraudes

### 4. **F1-Score**
- Balance entre precision y recall
- √ötil con clases desbalanceadas
- Media arm√≥nica (penaliza valores extremos)

### 5. **Matriz de Confusi√≥n**
- Vista detallada de todos los tipos de errores
- Identifica qu√© clases se confunden
- Base para calcular otras m√©tricas

---

## Posibles Mejoras y Extensiones

1. **Validaci√≥n Cruzada** (Cross-Validation)
   ```python
   from sklearn.model_selection import cross_val_score
   scores = cross_val_score(tree_instance, X, Y, cv=5)
   print(f"Scores: {scores}")
   print(f"Promedio: {scores.mean():.4f} (+/- {scores.std():.4f})")
   ```

2. **Optimizaci√≥n de Hiperpar√°metros**
   ```python
   from sklearn.model_selection import GridSearchCV
   params = {
       'max_depth': [2, 3, 4, 5, 6],
       'min_samples_split': [2, 5, 10],
       'min_samples_leaf': [1, 2, 4]
   }
   grid = GridSearchCV(DecisionTreeClassifier(), params, cv=5)
   grid.fit(X_train, Y_train)
   print(f"Mejores par√°metros: {grid.best_params_}")
   ```

3. **Feature Importance (Importancia de Caracter√≠sticas)**
   ```python
   importances = tree_instance.feature_importances_
   feature_importance_df = pd.DataFrame({
       'Feature': X.columns,
       'Importance': importances
   }).sort_values('Importance', ascending=False)
   print(feature_importance_df)
   ```

4. **Curva ROC y AUC** (para clasificaci√≥n binaria)
   ```python
   from sklearn.metrics import roc_curve, auc
   from sklearn.preprocessing import label_binarize
   # √ötil para evaluar modelos binarios
   ```

5. **Random Forest** (Mejora del Decision Tree)
   ```python
   from sklearn.ensemble import RandomForestClassifier
   rf_model = RandomForestClassifier(n_estimators=100, max_depth=3)
   rf_model.fit(X_train, Y_train)
   rf_pred = rf_model.predict(X_test)
   print(f"Accuracy RF: {accuracy_score(Y_test, rf_pred)}")
   ```

6. **Comparaci√≥n de M√∫ltiples Modelos**
   ```python
   from sklearn.svm import SVC
   from sklearn.neighbors import KNeighborsClassifier
   
   modelos = {
       'Decision Tree': DecisionTreeClassifier(max_depth=2),
       'Random Forest': RandomForestClassifier(n_estimators=100),
       'SVM': SVC(kernel='rbf'),
       'KNN': KNeighborsClassifier(n_neighbors=5)
   }
   
   for nombre, modelo in modelos.items():
       modelo.fit(X_train, Y_train)
       pred = modelo.predict(X_test)
       acc = accuracy_score(Y_test, pred)
       print(f"{nombre}: {acc:.4f}")
   ```

---

## Conclusiones del An√°lisis

### Ventajas del Modelo Implementado
‚úÖ **Alta interpretabilidad**: El √°rbol es visual y f√°cil de explicar
‚úÖ **Entrenamiento r√°pido**: Pocas computaciones necesarias
‚úÖ **Buena precisi√≥n**: Con solo 2 niveles obtiene buenos resultados
‚úÖ **No requiere normalizaci√≥n**: Los √°rboles no necesitan escalar datos
‚úÖ **M√©tricas completas**: Evaluaci√≥n exhaustiva del rendimiento

### Limitaciones Identificadas
‚ö†Ô∏è **Profundidad limitada**: max_depth=2 puede perder patrones complejos
‚ö†Ô∏è **Sensibilidad al split**: Diferentes random_state dan diferentes resultados
‚ö†Ô∏è **Overfitting potencial**: Sin validaci√≥n cruzada
‚ö†Ô∏è **No usa todas las caracter√≠sticas**: Solo las m√°s discriminantes

### Recomendaciones para Producci√≥n
1. Implementar validaci√≥n cruzada
2. Optimizar hiperpar√°metros con GridSearch
3. Probar Random Forest para mayor robustez
4. An√°lizar feature importance
5. Guardar modelo entrenado (pickle/joblib)
6. Monitorear performance en datos nuevos

---

## Recursos Adicionales

- [Documentaci√≥n Decision Trees - Scikit-learn](https://scikit-learn.org/stable/modules/tree.html)
- [Understanding Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)
- [Precision vs Recall](https://en.wikipedia.org/wiki/Precision_and_recall)
- [Wine Dataset UCI](https://archive.ics.uci.edu/ml/datasets/wine)ams = {'max_depth': [2, 3, 4, 5]}
   grid = GridSearchCV(DecisionTreeClassifier(), params, cv=5)
   ```

4. **Feature Importance**
   ```python
   importances = tree_instance.feature_importances_
   ```

5. **Normalizaci√≥n de Datos**
   ```python
   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   X_scaled = scaler.fit_transform(X)
   ```
