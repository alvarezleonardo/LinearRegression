# ğŸ· ClasificaciÃ³n de Vinos con Ãrboles de DecisiÃ³n

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un modelo de **Machine Learning** para clasificaciÃ³n de vinos utilizando **Ãrboles de DecisiÃ³n** (Decision Trees) con el dataset de vinos de scikit-learn. 

### ğŸ¯ Objetivo Principal
Clasificar vinos en **3 categorÃ­as distintas** basÃ¡ndose en **13 caracterÃ­sticas quÃ­micas** mediante un algoritmo de aprendizaje supervisado.

### ğŸ”¬ MetodologÃ­a
- ImplementaciÃ³n de un clasificador Decision Tree
- DivisiÃ³n de datos en conjuntos de entrenamiento (75%) y prueba (25%)
- VisualizaciÃ³n del Ã¡rbol de decisiÃ³n para interpretaciÃ³n de resultados
- EvaluaciÃ³n del modelo mediante mÃ©tricas de precisiÃ³n

## ğŸ“Š Dataset

- **Nombre**: Wine Recognition Dataset (scikit-learn)
- **CaracterÃ­sticas**: 13 atributos quÃ­micos
  - Alcohol
  - Ãcido mÃ¡lico
  - Cenizas
  - Alcalinidad de las cenizas
  - Magnesio
  - Fenoles totales
  - Flavonoides
  - Fenoles no flavonoides
  - Proantocianinas
  - Intensidad de color
  - Matiz
  - OD280/OD315 de vinos diluidos
  - Prolina
- **Clases**: 3 tipos de vinos (cultivares diferentes)
- **Total de muestras**: 178 observaciones
- **Balanceo**: Dataset relativamente balanceado entre las 3 clases

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| LibrerÃ­a | VersiÃ³n Recomendada | PropÃ³sito |
|----------|---------------------|-----------|
| **Python** | 3.8+ | Lenguaje de programaciÃ³n base |
| **NumPy** | 1.21+ | Operaciones numÃ©ricas y manejo de arrays |
| **Pandas** | 1.3+ | ManipulaciÃ³n y anÃ¡lisis de datos |
| **Scikit-learn** | 1.0+ | Algoritmos de Machine Learning y preprocesamiento |
| **Matplotlib** | 3.4+ | VisualizaciÃ³n de datos y grÃ¡ficos |
| *ğŸ“ Estructura del Proyecto

```
Ejercicio 1/
â”‚
â”œâ”€â”€ ejercicio1.ipynb           # ğŸ““ Notebook principal con el anÃ¡lisis completo
â”‚                               #    Incluye celdas markdown explicativas
â”‚
â”œâ”€â”€ README.md                  # ğŸ“– Este archivo - DocumentaciÃ³n general
â”‚
â”œâ”€â”€ explicacion_librerias.md  # ğŸ“š ExplicaciÃ³n detallada de las librerÃ­as utilizadas
â”‚ğŸ’» InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos
- Python 3.8 o superior instalado
- pip (gestor de paquetes de Python)
- Jupyter Notebook o JupyterLab

### InstalaciÃ³n de Dependencias

#### OpciÃ³n 1: InstalaciÃ³n individual
```bash
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

#### OpciÃ³n 2: InstalaciÃ³n desde requirements.txt (recomendado)
```bash
# Crear archivo requirements.txt con:
# nğŸ“ˆ Resultados Esperados

El modelo de Ãrbol de DecisiÃ³n con profundidad mÃ¡xima de 2 niveles proporciona:

- âœ… **Alta interpretabilidad**: El Ã¡rbol es fÃ¡cil de entender y visualizar
- ğŸ“Š **Buena precisiÃ³n**: Accuracy que supera el 85% (verificar en notebook)
- ğŸ¯ **ClasificaciÃ³n multiclase**: Distingue entre 3 tipos de vinos
- ğŸš€ **Entrenamiento rÃ¡pido**: Modelo ligero y eficiente

### MÃ©tricas de EvaluaciÃ³n
La precisiÃ³n (accuracy) del modelo se calcula comparando las predicciones con las etiquetas reales del conjunto de prueba. El resultado especÃ­fico se encuentra en la Ãºltima celda del notebook.

## âš™ï¸ CaracterÃ­sticas TÃ©cnicas del Modelo

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| **Algoritmo** | DecisionTreeClassifier | Clasificador de scikit-learn |
| **Profundidad mÃ¡xima** | 2 niveles | Evita sobreajuste, mejora generalizaciÃ³n |
| **DivisiÃ³n de datos** | 75% / 25% | Train-test split |
| **Random state** | 1 | Garantiza reproducibilidad |
| **Criterio** | Gini (default) | Medida de impureza para divisiones |
ğŸ“ Aprendizajes Clave

Este proyecto permite comprender:

1. **Algoritmos de clasificaciÃ³n supervisada**: CÃ³mo funcionan los Ã¡rboles de decisiÃ³n
2. **Preprocesamiento de datos**: DivisiÃ³n train-test y exploraciÃ³n de datos
3. **EvaluaciÃ³n de modelos**: MÃ©tricas de rendimiento y validaciÃ³n
4. **VisualizaciÃ³n**: RepresentaciÃ³n grÃ¡fica de modelos de ML
5. **Scikit-learn**: Uso de la biblioteca estÃ¡ndar de ML en Python

## ğŸ”„ Posibles Mejoras

Ideas para extender este proyecto:

- [ ] Probar diferentes valores de `max_depth` y comparar resultados
- [ ] Implementar validaciÃ³n cruzada (cross-validation)
- [ ] Agregar mÃ¡s mÃ©tricas: precision, recall, F1-score, matriz de confusiÃ³n
- [ ] Comparar con otros algoritmos: Random Forest, SVM, KNN
- [ ] Realizar feature importance analysis
- [ ] Implementar grid search para optimizaciÃ³n de hiperparÃ¡metros
- [ ] Agregar visualizaciones adicionales (distribuciones, correlaciones)

## ğŸ“š Referencias

- [DocumentaciÃ³n de Scikit-learn - Decision Trees](https://scikit-learn.org/stable/modules/tree.html)
- [Wine Dataset UCI](https://archive.ics.uci.edu/ml/datasets/wine)
- [Ãrboles de DecisiÃ³n - TeorÃ­a](https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n)

## ğŸ¤ Contribuciones

Este es un proyecto educativo. Si encuentras errores o tienes sugerencias:
1. Abre un issue
2. PropÃ³n mejoras
3. Comparte tus resultados

## ğŸ“„ Licencia

Proyecto educativo - Digital House Data Science

## ğŸ‘¤ Autor

**Digital House Data Science - Ejercicio 1**

ğŸ“… **Fecha**: Diciembre 2025

---

â­ Si este proyecto te fue Ãºtil, no olvides darle una estrella!

ğŸ’¡ **Tip**: Experimenta modificando los parÃ¡metros del modelo para ver cÃ³mo afectan los resultados.
## ğŸ“Š VisualizaciÃ³n

El proyecto incluye una visualizaciÃ³n completa del Ã¡rbol de decisiÃ³n que muestra:

- ğŸŒ³ **Estructura del Ã¡rbol**: Nodos de decisiÃ³n y hojas
- ğŸ“ **CaracterÃ­sticas clave**: Variables mÃ¡s importantes para la clasificaciÃ³n
- ğŸ”€ **Reglas de decisiÃ³n**: Umbrales de divisiÃ³n en cada nodo
- ğŸ¨ **CodificaciÃ³n por colores**: 
  - Colores diferentes representan las 3 clases de vinos
  - Intensidad del color indica la pureza de la clasificaciÃ³n
- ğŸ“Š **DistribuciÃ³n de muestras**: Cantidad de ejemplos en cada nodo
source venv/bin/activate
# En Windows:
venv\Scripts\activate

# Instalar dependencias
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

## ğŸš€ EjecuciÃ³n

### MÃ©todo 1: Jupyter Notebook ClÃ¡sico
```bash
# Navegar al directorio del proyecto
cd "Digital House Data Science/Ejercicio 1"

# Iniciar Jupyter Notebook
jupyter notebook

# Se abrirÃ¡ automÃ¡ticamente en tu navegador
# Haz clic en ejercicio1.ipynb
```

### MÃ©todo 2: JupyterLab (interfaz moderna)
```bash
jupyter lab
```

### MÃ©todo 3: Visual Studio Code
1. Instalar la extensiÃ³n "Jupyter" en VS Code
2. Abrir el archivo `ejercicio1.ipynb`
3. Seleccionar el kernel de Python adecuado
4. Ejecutar las celdas secuencialmente con `Shift + Enter`

### âš ï¸ Importante
- Ejecutar las celdas en **orden secuencial** de arriba hacia abajo
- Cada celda depende de las anteriores
- Las celdas markdown proporcionan contexto y explicaciones
9. **EvaluaciÃ³n**: CÃ¡lculo de mÃ©tricas de rendimiento README.md                  # Este archivo
â”œâ”€â”€ explicacion_librerias.md  # ExplicaciÃ³n detallada de las librerÃ­as
â””â”€â”€ explicacion_codigo.md     # AnÃ¡lisis paso a paso del cÃ³digo
```

## InstalaciÃ³n

Para ejecutar este proyecto, necesitas instalar las siguientes dependencias:

```bash
pip install numpy pandas scikit-learn matplotlib seaborn jupyter
```

## EjecuciÃ³n

1. Abre Jupyter Notebook:
```bash
jupyter notebook
```

2. Navega hasta `ejercicio1.ipynb` y ejecuta las celdas secuencialmente.

## Resultados

El modelo de Ãrbol de DecisiÃ³n con profundidad mÃ¡xima de 2 niveles logra clasificar los vinos con una precisiÃ³n que se puede consultar en la Ãºltima celda del notebook.

## CaracterÃ­sticas del Modelo

- **Algoritmo**: Decision Tree Classifier
- **Profundidad mÃ¡xima**: 2 niveles
- **DivisiÃ³n de datos**: 75% entrenamiento, 25% prueba
- **Random state**: 1 (para reproducibilidad)

## VisualizaciÃ³n

El proyecto incluye visualizaciÃ³n del Ã¡rbol de decisiÃ³n, mostrando:
- CaracterÃ­sticas utilizadas en cada nodo
- Decisiones de clasificaciÃ³n
- Colores que representan las clases

## Autor

Digital House Data Science - Ejercicio 1

## Fecha

Diciembre 2025
